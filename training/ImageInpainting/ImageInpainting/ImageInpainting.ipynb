{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use if main package is not in python path\n",
    "# import os, sys\n",
    "# sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd()))))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.datasets import TrainSetIntact\n",
    "from models.models_GatedUNet import GatedUNet\n",
    "from models.BinaryInpainting_forward import BinaryInpainting\n",
    "from models.cpn_custom_forward_2 import CPN\n",
    "from training_funcs import train, sample_II\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42);\n",
    "\n",
    "n_gpus = torch.cuda.device_count()\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
    "print(f\"Using GPU: {cuda}\")\n",
    "print(f\"Available GPUs: {n_gpus}\")\n",
    "print(\"Only tested with CUDA enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note on this model: The training results are inconsistent and very sensitive to hyperparameter changes. \n",
    "$\\beta_1 \\leq 0.8$ in the Adam optimizers seems to very important for training stability in runs longer than 20-30\n",
    "epochs. The results are less sensitive to small changes in width unit or learning rates. It is unclear what causes\n",
    "artifacting to appear in specific examples and how to prevent it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crop_dim = 256  # Quadratic dimension of the image crops (should be divisible by 32 to avoid cuda error with demics/pad)\n",
    "\n",
    "bs = 32\n",
    "lr = 1e-4\n",
    "epochs = 200\n",
    "\n",
    "G = GatedUNet(1, 1, 32, crop_dim, dilation=True, condition_channels=3,\n",
    "          kernel_size=3, padding=1, padding_mode=\"reflect\")\n",
    "D = GatedUNet(1, 1, 32, crop_dim, condition_channels=1, leaky=True, sn=True,\n",
    "          kernel_size=3, padding=1, padding_mode=\"reflect\")\n",
    "\n",
    "if cuda:\n",
    "    G = G.cuda(device)\n",
    "    D = D.cuda(device)\n",
    "\n",
    "G_opt = optim.Adam(G.parameters(), lr=4*lr, betas=(0.5,0.999))\n",
    "D_opt = optim.Adam(D.parameters(), lr=lr, betas=(0.5,0.999))\n",
    "\n",
    " \n",
    "train_data = TrainSetIntact(1000, crop_dim, n_test=1, test=False)\n",
    "train_loader = DataLoader(train_data, batch_size=bs, shuffle=False, num_workers=0, drop_last=False, pin_memory=True)\n",
    "\n",
    "test_data = TrainSetIntact(100, crop_dim, n_test=1, test=True)\n",
    "test_loader = DataLoader(test_data, batch_size=bs, shuffle=False, num_workers=0, drop_last=False, pin_memory=True)\n",
    "\n",
    "\n",
    "print(f\"Generator Number of Parameters: {G.count_parameters():,}\")\n",
    "print(f\"Discriminator Number of Parameters: {D.count_parameters():,}\")\n",
    "\n",
    "cpn = CPN(cuda, device, order=2)\n",
    "BI = BinaryInpainting(cuda, device, max_len=192)\n",
    "\n",
    "hists = train(train_loader, test_loader, epochs, G, G_opt, D, D_opt, BI, cpn, cuda, device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(G.state_dict(), \"model_saves/G_GatedUNet_GatedUNet.pt\")\n",
    "# torch.save(D.state_dict(), \"model_saves/D_GatedUNet_GatedUNet.pt\")\n",
    "# torch.save(hists, \"model_saves/loss_hists/GatedUNet_GatedUNet_hists.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_loss_hist = hists[\"D_loss_hist\"]\n",
    "D_acc_true_hist = hists[\"D_acc_true_hist\"]\n",
    "D_acc_fake_hist = hists[\"D_acc_fake_hist\"]\n",
    "adv_loss_hist = hists[\"adv_loss_hist\"]\n",
    "con_loss_hist = hists[\"con_loss_hist\"]\n",
    "\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Losses\")\n",
    "plt.plot(D_loss_hist)\n",
    "plt.plot(adv_loss_hist)\n",
    "plt.plot(con_loss_hist)\n",
    "plt.legend([\"D-Loss\", \"Adv-Loss\", \"Con-Loss\"])\n",
    "plt.ylim(bottom=0)\n",
    "plt.xlabel(f\"Iterations (Batch-Size {bs})\")\n",
    "plt.ylim([0,5])\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(D_acc_true_hist)\n",
    "plt.plot(D_acc_fake_hist)\n",
    "plt.plot(np.ones(len(D_acc_true_hist))*0.5, linestyle=\":\", color=\"black\")\n",
    "plt.legend([\"True Acc\", \"Fake Acc\"])\n",
    "plt.ylim([0,1])\n",
    "plt.xlabel(f\"Epochs ({1000} Examples per Epoch)\")\n",
    "# plt.savefig(\"imgs/GatedUNet_GatedUnet\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.amp.autocast() and torch.no_grad():\n",
    "    sample_II(loader, G, BI, cpn, cuda, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}