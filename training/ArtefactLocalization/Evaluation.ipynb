{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use if main package is not in python path\n",
    "# import os, sys\n",
    "# sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.datasets import TrainSetArtefacts\n",
    "from models.models_UNet import UNet\n",
    "from training_funcs import sample_P\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42);\n",
    "\n",
    "n_gpus = torch.cuda.device_count()\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
    "print(f\"Using GPU: {cuda}\")\n",
    "print(f\"Available GPUs: {n_gpus}\")\n",
    "print(\"Only tested with CUDA enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_dim = 384  # Quadratic dimension of the image crops\n",
    "\n",
    "wu = 16  # Width unit\n",
    "bs = 16\n",
    "\n",
    "predictor = UNet(1, 1, wu, crop_dim, 1, dilation=False, kernel_size=3, padding=1, bias=False, padding_mode=\"reflect\")\n",
    "print(f\"Predictor Number of Paramters: {predictor.count_parameters():,}\")\n",
    "\n",
    "if cuda:\n",
    "    predictor = predictor.cuda(device)\n",
    "    \n",
    "\n",
    "predictor.load_state_dict(torch.load(\"model_saves/predictor.pt\", map_location=device))\n",
    "predictor.to(device)\n",
    "predictor.eval()\n",
    "predictor.requires_grad_(False)\n",
    "\n",
    "test_data = TrainSetArtefacts(10000, crop_dim, n_test=10, test=True)\n",
    "test_loader = DataLoader(test_data, batch_size=bs, shuffle=False, num_workers=0, drop_last=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_hist = []\n",
    "acc_hist = np.zeros(0)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "start_time = time.time()        \n",
    "for it, (crop, anno) in enumerate(test_loader):  # Shapes: [bs, 1, crop_dim, crop_dim]\n",
    "    if cuda:\n",
    "        crop = crop.cuda(device)\n",
    "        anno = anno.cuda(device)\n",
    "\n",
    "    with torch.cuda.amp.autocast():\n",
    "        anno_pred = predictor(crop)\n",
    "        loss = criterion(anno_pred, anno.half())\n",
    "        pred = torch.round(torch.sigmoid(anno_pred))\n",
    "        acc = pred.eq_(anno.half()).mean(dim=(-1, -2))\n",
    "        acc = acc.squeeze(1).cpu().detach().numpy()\n",
    "\n",
    "    loss_hist.append(loss.item())\n",
    "    acc_hist = np.append(acc_hist, acc)\n",
    "print(f\"Evaluation finished after {time.time()-start_time:.1f}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(acc_hist, \"model_saves/eval_acc_hist\")\n",
    "acc_hist = torch.load(\"model_saves/eval_acc_hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "plt.title(\"Segmentation Accuracy\", size=15)\n",
    "bin_size = 1/500\n",
    "bins = np.arange(0.8, 1+bin_size, bin_size)\n",
    "plt.hist(acc_hist, bins, label=\"Sample Accuracy\")\n",
    "y_max = plt.gca().get_yticks()[-2]\n",
    "plt.vlines(np.mean(acc_hist), 0, y_max, linestyle=\"--\", color=\"black\", label=\"Mean Accuracy\")\n",
    "plt.xlabel(f\"Annotation Coverage (bin size {bin_size})\", size=12)\n",
    "plt.ylabel(\"No. of Occurences\", size=12)\n",
    "plt.gca().set_xticklabels([f\"{x*100:.1f}%\" for x in plt.gca().get_xticks()])\n",
    "plt.legend()\n",
    "# plt.savefig(\"hparam_tuning_imgs/AL_eval.png\", dpi=200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.amp.autocast():\n",
    "    sample_P(test_loader, predictor, cuda=cuda, device=device, plot=True, save_as=None, seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
